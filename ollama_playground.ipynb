{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634f78e0",
   "metadata": {},
   "source": [
    "## This is playground repo to play around with local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ab1bce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c45c2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProgressResponse(status='success', completed=None, total=None, digest=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_NAME = \"phi3\" # will try this one first then maybe \"qwen:3b\"\n",
    "ollama.pull(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc09cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt: str) -> str:\n",
    "    response = ollama.chat(\n",
    "        model = MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        options={\n",
    "            \"temperature\": 0.7,\n",
    "            \"num_predict\": 512,\n",
    "        }\n",
    "    )\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c43198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a string of code here with no feelings or physical form, so I don't experience days the way humans do. However, if I were to simulate an answer: \"I'm functioning optimally and ready for our interaction! How can I help you today?\"\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(\"Hello Ollama, how are you today?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2569b41",
   "metadata": {},
   "source": [
    "### Let's try streaming!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3873025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_streaming(prompt: str):\n",
    "    stream = ollama.chat(\n",
    "        model = MODEL_NAME,\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt\n",
    "        }],\n",
    "        stream=True,\n",
    "        options={\n",
    "            \"temparature\": 0.7,\n",
    "            \"num_predict\": 256\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    full = []\n",
    "    for chunk in stream:\n",
    "        content = chunk['message']['content']\n",
    "        print(content, end=\"\", flush=True)\n",
    "        full.append(content)\n",
    "    print()\n",
    "    return \"\".join(full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295ad03d",
   "metadata": {},
   "source": [
    "If you run it now, you can see how tokens are returning as they are generated, not all at once in the end, this is important feature for UX, and most of chat interfaces use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66aeeca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The color of the sky appears predominantly blue due to a phenomenon called Rayleigh scattering. This effect occurs when molecules and small particles in Earth's atmosphere interact with sunlight, causing shorter wavelength light (blue) to scatter more than longer wavelength light (red). Since our eyes are most sensitive to the green-yellow part of the spectrum, we perceive that color as being \"whitish\" or blue.\n",
      "\n",
      "When there are fewer particles in the atmosphere, such as on clear sunny days with little pollution and moisture content—like during a dry day without rain clouds present —the sky appears even bluer because less light is absorbed before it reaches our eyes. However, when there'selavent occurs more atmospheric particulates like dust or water droplets from cloud formation due to humidity increases the scattering and reflection of sunlight in all directions which can lead to a whiter sky with possible pinkish undertones during events such as halos around the sun.\n",
      "\n",
      "During twilight periods, when some direct light reaches Earth's surface while also reflecting off clouds or atmospheric particles (known as Mie scattering), we may observe sh\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The color of the sky appears predominantly blue due to a phenomenon called Rayleigh scattering. This effect occurs when molecules and small particles in Earth\\'s atmosphere interact with sunlight, causing shorter wavelength light (blue) to scatter more than longer wavelength light (red). Since our eyes are most sensitive to the green-yellow part of the spectrum, we perceive that color as being \"whitish\" or blue.\\n\\nWhen there are fewer particles in the atmosphere, such as on clear sunny days with little pollution and moisture content—like during a dry day without rain clouds present —the sky appears even bluer because less light is absorbed before it reaches our eyes. However, when there\\'selavent occurs more atmospheric particulates like dust or water droplets from cloud formation due to humidity increases the scattering and reflection of sunlight in all directions which can lead to a whiter sky with possible pinkish undertones during events such as halos around the sun.\\n\\nDuring twilight periods, when some direct light reaches Earth\\'s surface while also reflecting off clouds or atmospheric particles (known as Mie scattering), we may observe sh'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_streaming('Why sky is blue?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5915d3a4",
   "metadata": {},
   "source": [
    "### Let's try simple chat loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1fd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat with phi3. Type 'exit' to quit.\n"
     ]
    }
   ],
   "source": [
    "def chat_loop(model=MODEL_NAME, temperature=1.1, num_predict=256):\n",
    "    history=[]\n",
    "    print(f\"Starting chat with {model}. Type 'exit' to quit.\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"> \")\n",
    "        if user_input.strip().lower() in {\"exit\", \"\\\\q\", \"\\\\quit\"}:\n",
    "            print('ending chat...')\n",
    "            break\n",
    "        \n",
    "        history.append({'role': 'user', 'content': user_input})\n",
    "    \n",
    "        stream = ollama.chat(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_input,\n",
    "            }],\n",
    "            options={\n",
    "                \"temperature\": temperature, # try more randomness\n",
    "                \"num_predict\": num_predict\n",
    "            },\n",
    "            stream=True,\n",
    "        )\n",
    "        full = []\n",
    "        for chunk in stream:\n",
    "            content = chunk['message']['content']\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full.append(content)\n",
    "        print()\n",
    "        \n",
    "        assistant_message = full[\"message\"][\"content\"]\n",
    "        history.append({'role': 'assistant', 'content': assistant_message})\n",
    "        #print(f\"model: {assistant_message}\")\n",
    "        \n",
    "# chat_loop()\n",
    "# run chat_loop.py in terminal to have interactive chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d918c8c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
